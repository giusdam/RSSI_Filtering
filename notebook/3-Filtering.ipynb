{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd25833",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cca09f",
   "metadata": {},
   "source": [
    "The instability of RSSI based requires the application of some filter algorithms. Here, we describe and apply the filters selected to the data set obtained. Specifically, wepresent a brief explanation of the theory behind each filter, the related function implementation,and an evaluation of their performance. Finally, a comparison between the different filtered valuesis proposed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b402acf0",
   "metadata": {},
   "source": [
    "Importing libraries and reading the downsampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75828cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "df = pd.read_csv('../dataset/resample_mean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ce5873",
   "metadata": {},
   "source": [
    "## Grey Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef92ce81",
   "metadata": {},
   "source": [
    "Grey filters are based on the grey system theory, an interdisciplinary scientific area introduced byJulong Deng at the Huazhong University of Science and Technology in 1982.  In system theory,a system can be defined with a color representing the amount of clear information about it.  Acompletely unknown system is defined as a black system, while a white system is a completelyknown one. Similarly, systems with both known and unknown information are referred to as greysystems, representing the most common case since there are always some uncertainties in the realworld.  In this context, we define the grey models as models that can estimate the behavior of anunknown system only using a limited amount of data.  Precisely, they can predict the values offuture data based only on a set of the most recent data using a curve fitting approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e8c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grey filter taking in input the signal to filter, the time index and the windows size\n",
    "# Return the filtered signal\n",
    "\n",
    "def grey_filter(signal, index, N):\n",
    "    filtered_signal = []\n",
    "\n",
    "    # iterates on the entire signal, taking steps by window size\n",
    "    for j in range(0, np.shape(signal)[0], N):    \n",
    "\n",
    "        # just in case we are at signal final and N samples are not available\n",
    "        N = np.minimum(N, np.shape(signal)[0]-j)  \n",
    "\n",
    "        # saves in R_0 signal values of corresponding window size\n",
    "        R_0 = np.zeros(N)\n",
    "        R_0[:] = signal[j:j+N]                     \n",
    "        \n",
    "        # calculates R_1\n",
    "        R_1 = []\n",
    "        for i in range(N):\n",
    "            R_1.append((np.cumsum(R_0[0:i+1]))[i])  \n",
    "\n",
    "        # calculates grey filter solution\n",
    "        B = (np.matrix([np.ones((N-1)), np.ones((N-1))])).T\n",
    "        for k in range(N-1):\n",
    "            B[k, 0] = -0.5 * (R_1[k+1] + R_1[k])\n",
    "\n",
    "        X_n = np.matrix(np.asarray(R_0[1:])).T\n",
    "        _ = np.matmul(np.linalg.pinv(\n",
    "                np.matmul(B.T, B)),\n",
    "                      (np.matmul(B.T, X_n)))\n",
    "        \n",
    "        a = _[0, 0]\n",
    "        u = _[1, 0]\n",
    "\n",
    "        # updates predicted signal with window calculations\n",
    "        X_ = R_0[0]\n",
    "        filtered_signal.append(X_)\n",
    "        for i in range(1, N):                                             \n",
    "            filtered_signal.append((((R_0[0] - u/a) * np.exp(-a * (i - 1)))*(1 - np.exp(a))))\n",
    "    \n",
    "    # transforms the data into dataframe with the time index\n",
    "    df_filtered = pd.DataFrame(filtered_signal, columns=['rssi'])\n",
    "    df_filtered = df_filtered.join(index)\n",
    "        \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4212fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "grey_filtered = grey_filter(df['rssi'], df['Time'], N=5)\n",
    "grey_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e35c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "grey_filtered.plot(x='Time',xlabel='Time', y='rssi', ylabel='RSSI', title='Grey filter', figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df809133",
   "metadata": {},
   "source": [
    "We compare the filtered values obtained with the grey filter function with the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa336bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "plt.plot(df['rssi'], label='Raw')\n",
    "plt.plot(grey_filtered['rssi'], label='Grey', linestyle='dashed')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('RSSI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364737fc",
   "metadata": {},
   "source": [
    "The figure shows that the grey filter is able to reduce the fluctuation, especially when there are high or low peaks. However, the filter is sensitive to quick changes in data since the line still has significant fluctuations and even some new ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21e6271",
   "metadata": {},
   "source": [
    "## Kalman Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c46ebe4",
   "metadata": {},
   "source": [
    "The Kalman filter was invented by Rudolf Emil Kálmán at the Research Institute for Advanced Study in 1960 to solve the discrete-data linear filtering problems in a mathematically optimal way.\n",
    "The first use of the Kalman filter was on the Apollo missions, and since then, it has been used in an enormous variety of domains. The relative simplicity and robust nature of the filter have ensured the success of the Kalman filter.\n",
    "The Kalman filter is essentially a set of mathematical equations that implement an optimal predictor-corrector type estimator. The term optimal is used because the function minimizes the estimated error covariance when some presumed conditions are met.\n",
    "The Kalman filter exploits the target dynamics, i.e., its time evolution, to remove the effects of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc9f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kalman filter taking in input the signal to filter, the time index and the filter parameters\n",
    "# Return the filtered signal\n",
    "\n",
    "def kalman_block(x, P, s, A, H, Q, R):\n",
    "    x_mean = A * x + np.random.normal(0, Q, 1)\n",
    "    P_mean = A * P * A + Q\n",
    "\n",
    "    K = P_mean * H * (1 / (H * P_mean * H + R))\n",
    "    x = x_mean + K * (s - H * x_mean)\n",
    "    P = (1 - K * H) * P_mean\n",
    "\n",
    "    return x, P\n",
    "\n",
    "def kalman_filter(signal, index, A, H, Q, R):\n",
    "    filtered_signal = []\n",
    "    # takes first value as first filter prediction\n",
    "    x = signal[0]\n",
    "    # sets first covariance state value to zero\n",
    "    P = 0                                         \n",
    "\n",
    "    filtered_signal.append(x)\n",
    "    # iterates on the entire signal, except the first element\n",
    "    for j, s in enumerate(signal[1:]):            \n",
    "        # calculates next state prediction\n",
    "        # x: previous mean state\n",
    "        # P: previous covariance state\n",
    "        # s: current observation\n",
    "        x, P = kalman_block(x, P, s, A, H, Q, R)\n",
    "        # updates predicted signal with this step calculation\n",
    "        filtered_signal.append(x[0])\n",
    "\n",
    "    df_filtered = pd.DataFrame(filtered_signal, columns=['rssi'])\n",
    "    df_filtered = df_filtered.join(index)\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba3bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kalman_filtered = kalman_filter(df['rssi'], df['Time'],  A=1, H=1, Q=1.6, R=6)\n",
    "kalman_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6783440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kalman_filtered.plot(x='Time',xlabel='Time', y='rssi', ylabel='RSSI', title='Kalman filter', figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848b7660",
   "metadata": {},
   "source": [
    "We compare the filtered values obtained with the Kalman filter function with the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627fe542",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "plt.plot(df['rssi'], linestyle='dashed', label='Raw')\n",
    "plt.plot(kalman_filtered['rssi'], label='Kalman')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('RSSI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153aa687",
   "metadata": {},
   "source": [
    "The Kalman filter provides a good fluctuations mitigation and is able to follow the time evolution without amplifying many rapid changes in the values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcae6378",
   "metadata": {},
   "source": [
    "## Fourier filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7de603",
   "metadata": {},
   "source": [
    "The Fourier filter is a filtering function used in signal processing based on manipulating specific frequency components of a signal exploiting the Fourier transform. A Fourier transform is\n",
    "a mathematical transform that decomposes functions depending on space or time into functions depending on spatial or temporal frequency. However, the Fourier transform requires a considerable number of operations making the computation prohibitively expensive. The Fast Fourier transform addresses this problem, reducing the complexity introducing a memory portion within the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dfd751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourier filter taking in input the signal to filter, the time index, the windows size\n",
    "# and the number of sample to preserve\n",
    "# Return the filtered signal\n",
    "\n",
    "def fft_filter(signal, index, N, M):\n",
    "    filtered_signal = []\n",
    "\n",
    "    for j in range(0, np.shape(signal)[0], N):      \n",
    "        # just in case we are at signal final and N samples are not avail\n",
    "        N = np.minimum(N, np.shape(signal)[0] - j)  \n",
    "\n",
    "        # saves in R_0 signal values of corresponding window size\n",
    "        R_0 = np.zeros(N)\n",
    "        R_0[:] = signal[j:j+N]                       \n",
    "\n",
    "        # fft of signal window\n",
    "        R_0_fft = np.fft.fft(R_0)                    \n",
    "\n",
    "        # it keeps M samples of fft and sets the rest to zero\n",
    "        # remembers fft symmetry\n",
    "        for k in range(int(N / 2)):                    \n",
    "            R_0_fft[M+k] = 0                         \n",
    "            R_0_fft[-1-M-k] = 0\n",
    "\n",
    "        # inverse fft\n",
    "        R_0_ifft = np.fft.ifft(R_0_fft)              \n",
    "\n",
    "        # updates predicted signal with this window calculation\n",
    "        for i in range(0, N):\n",
    "            filtered_signal.append(R_0_ifft[i])     \n",
    "\n",
    "    df_filtered = pd.DataFrame(filtered_signal, columns=['rssi'])\n",
    "    df_filtered = df_filtered.join(index)\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f32bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_filtered = fft_filter(df['rssi'], df['Time'], N=6, M=2)\n",
    "fft_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd44c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_filtered.plot(x='Time',xlabel='Time', y='rssi', ylabel='RSSI', title='Fourier filter', figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3656815",
   "metadata": {},
   "source": [
    "We compare the filtered values obtained with the Fourier filter function with the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d51c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "plt.plot(df['rssi'], linestyle='dashed', label='Raw')\n",
    "plt.plot(fft_filtered['rssi'], label='Fourier')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('RSSI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d604b8f",
   "metadata": {},
   "source": [
    "The Fourier filter provides a significantly smoother line than the raw data reducing the fluctuations and following the time sequence without any amplification of the signal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755500a6",
   "metadata": {},
   "source": [
    "## Particle filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0902e760",
   "metadata": {},
   "source": [
    "Particle filters are algorithms used to solve filtering problems arising in signal processing and Bayesian statistical inference. The term particle filters were first coined in 1996 by Del Moral in reference to mean-field interacting particle methods used in fluid mechanics since the beginning of the 1960s.\n",
    "Particle filters use a set of particles, also called samples, to represent the posterior distribution of some stochastic process given noisy or partial observations. Each particle has a weight representing the probability of being sampled from the probability function. In the resampling step, the particles with negligible weights are replaced by new particles in the proximity of the particles with higher weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0241f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Particle filter taking in input the signal to filter, the time index, the number of particles,\n",
    "# and the filter parameters\n",
    "# Return the filtered signal\n",
    "\n",
    "def choose_particle(particles):\n",
    "    prob_distribution = []\n",
    "\n",
    "    # calculates sum of weights to normalize wheight vector in next step\n",
    "    sum_weights = 0\n",
    "    for p in particles:\n",
    "        sum_weights += p['weight']\n",
    "\n",
    "    for p in particles:\n",
    "        prob_distribution.append(float(p['weight'] / sum_weights))\n",
    "\n",
    "    # choose particle according to weights distribution\n",
    "    a = np.random.choice(particles, 1, replace=False, p=prob_distribution)\n",
    "\n",
    "    return a[0]['value'][0]\n",
    "\n",
    "\n",
    "def particle_filter(signal, index, quant_particles, A, H, Q, R):\n",
    "\n",
    "    filtered_signal = []\n",
    "    # variation range of particles for initial step\n",
    "    rang = 10                                                  \n",
    "    # takes first value as first filter prediction\n",
    "    x = signal[0]                                              \n",
    "    # sets first covariance state value to zero\n",
    "    P = 0                                                      \n",
    "\n",
    "    filtered_signal.append(x)\n",
    "    # defines some needed constants in algorithm\n",
    "    min_weight_to_consider = 0.07                              \n",
    "    min_weight_to_split_particle = 5\n",
    "\n",
    "    # iterates on the entire signal, except the first element\n",
    "    for j, s in enumerate(signal[1:]):                         \n",
    "        # sets variation range for first step sampling\n",
    "        range_ = [filtered_signal[j-1] - rang,\n",
    "        filtered_signal[j-1] + rang]                \n",
    "\n",
    "        particles = []\n",
    "        # loop on all particles\n",
    "        for particle in range(quant_particles):                \n",
    "            # sample particle value from variation range\n",
    "            input = np.random.uniform(range_[0], range_[1])\n",
    "            # particle weight\n",
    "            weight = 1 / np.abs(input-x)                       \n",
    "\n",
    "            # it only iterates on particles which weights are greater than _min_weight_to_consider_\n",
    "            if weight > min_weight_to_consider:\n",
    "                # calculates next state prediction\n",
    "                x_, P = kalman_block(input, P, s, A, H, Q, R)  \n",
    "\n",
    "                # prediction weight\n",
    "                weight = 1 / np.abs(s - x_)                    \n",
    "                particles.append({'value': x_, 'weight': weight})\n",
    "\n",
    "                # for particles with greater weights, it creates other particles in the 'neighborhood'\n",
    "                if weight > min_weight_to_split_particle:\n",
    "\n",
    "                    input = input + np.random.uniform(0, 5)\n",
    "                    x_, P = kalman_block(input, P, s, A, H, Q, R)\n",
    "\n",
    "                    weight = 1 / np.abs(s - x_)\n",
    "                    particles.append({'value': x_, 'weight': weight})\n",
    "\n",
    "        # chooses a particle, according to weight distribution\n",
    "        x = choose_particle(particles)                      \n",
    "\n",
    "        # updates predicted signal with this step calculation\n",
    "        filtered_signal.append(x)                             \n",
    "\n",
    "    df_filtered = pd.DataFrame(filtered_signal, columns=['rssi'])\n",
    "    df_filtered = df_filtered.join(index)\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2cfa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_filtered = particle_filter(df['rssi'], df['Time'], quant_particles=1000, A=1, H=1, Q=1.6, R=6)\n",
    "particle_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe85eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_filtered.plot(x='Time',xlabel='Time', y='rssi', ylabel='RSSI', title='Particle filter', figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a1977d",
   "metadata": {},
   "source": [
    "We compare the filtered values obtained with the particle filter function with the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7a7e3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "plt.plot(df['rssi'], linestyle='dashed', label='Raw')\n",
    "plt.plot(particle_filtered['rssi'], label='Particle')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('RSSI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7717e308",
   "metadata": {},
   "source": [
    "The figure shows that the Particle filter is not able to mitigate the signal fluctuations. It introduces peaks when the signal rapidly changes and is also the slowest to compute. Even tuning the parameter, the performance does not improve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f6707e",
   "metadata": {},
   "source": [
    "## Filters comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674dc987",
   "metadata": {},
   "source": [
    "We compare the data obtained from each filter implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e26ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "plt.plot(df['rssi'], linestyle='dotted', label='Raw')\n",
    "plt.plot(grey_filtered['rssi'],  label='Grey')\n",
    "plt.plot(kalman_filtered['rssi'], ls='dashed', label='Kalman')\n",
    "plt.plot(fft_filtered['rssi'], ls='dashdot',label='Fourier')\n",
    "plt.plot(particle_filtered['rssi'], ls='dotted', color='y', label='Particle')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('RSSI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee85a37a",
   "metadata": {},
   "source": [
    "The comparison confirms the comments made before. The Kalman and Fourier filters are the most promising, being able to smooth quite well the signal. The grey filter is able to mitigate the fluctuations in most cases but sometimes tends to introduce a new one when the signal has rapid changes. Finally, the particle filter performs the worst showing more fluctuations than the raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b8f48f",
   "metadata": {},
   "source": [
    "We perform another comparison, including only the Kalman and the Fourier filters and dropping the less effective ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5399cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "plt.plot(df['rssi'], ls='dotted', label='Raw')\n",
    "plt.plot(kalman_filtered['rssi'], linestyle='dashed', label='Kalman')\n",
    "plt.plot(fft_filtered['rssi'], linestyle='solid', label='Fourier')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('RSSI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ad86d1",
   "metadata": {},
   "source": [
    "The Kalman and the Fourier filters provide the best results. The Kalman algorithm is able to follow the actual RSSI value better, while the Fourier grants the smoothest line. The choice of which filters to use depends on the application requirements and the context."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
